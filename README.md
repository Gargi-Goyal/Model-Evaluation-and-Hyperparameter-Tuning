# Model-Evaluation-and-Hyperparameter-Tuning
Training multiple machine learning models and evaluating their performance using metrics such as accuracy, precision, recall, and F1-score. Implementing hyperparameter tuning techniques like GridSearchCV and RandomizedSearchCV to optimize model parameters. at last analyzing the results to select the best-performing model.
Goal: Identify the best-performing model for the Iris dataset through systematic evaluation and tuning.

âœ… **Multiple models which has been trained are:**
1) Logistic Regression
2) Decision Tree
3) Random Forest
4) SVM (Support Vector Machine)
5) KNN (K-Nearest Neighbors)

 **âœ¨ Features**
**Model Evaluation:**
1) Accuracy, Precision, Recall, F1-Score
2) Classification Reports
3) Confusion Matrices

 **Hyperparameter Tuning:**
1) Exhaustive search with GridSearchCV (Random Forest)
2) Randomized search with RandomizedSearchCV (SVM)

 **Visualization:**
1)Interactive plots (Matplotlib/Seaborn)
2) Model performance comparison bar charts

**ðŸ›  Technologies Used**
Python 3.x

**Libraries:**
scikit-learn (Models, Metrics, Tuning),
pandas (Data Handling),
numpy (Numerical Operations),
matplotlib/seaborn (Visualizations)

