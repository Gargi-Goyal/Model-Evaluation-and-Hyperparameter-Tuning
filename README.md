# Model-Evaluation-and-Hyperparameter-Tuning
Training multiple machine learning models and evaluating their performance using metrics such as accuracy, precision, recall, and F1-score. Implementing hyperparameter tuning techniques like GridSearchCV and RandomizedSearchCV to optimize model parameters. at last analyzing the results to select the best-performing model.
Goal: Identify the best-performing model for the Iris dataset through systematic evaluation and tuning.

âœ… **Multiple models which has been trained are:**
1) Logistic Regression
2) Decision Tree
3) Random Forest
4) SVM (Support Vector Machine)
5) KNN (K-Nearest Neighbors)

 **âœ¨ Features**
** Model Evaluation:**
Accuracy, Precision, Recall, F1-Score
Classification Reports
Confusion Matrices

 **Hyperparameter Tuning:**
Exhaustive search with GridSearchCV (Random Forest)
Randomized search with RandomizedSearchCV (SVM)

** Visualization:**
Interactive plots (Matplotlib/Seaborn)
Model performance comparison bar charts

** ðŸ›  Technologies Used**
Python 3.x

** Libraries:**
scikit-learn (Models, Metrics, Tuning)
pandas (Data Handling)
numpy (Numerical Operations)
matplotlib/seaborn (Visualizations)

